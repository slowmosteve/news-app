{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Topic Modeling\n",
    "\n",
    "This notebook is used to derive topics from news text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Activated [news-site].\n\n\nUpdates are available for some Cloud SDK components.  To install them,\nplease run:\n  $ gcloud components update\n\n"
    }
   ],
   "source": [
    "!gcloud config configurations activate news-site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_md\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 889 entries, 0 to 888\nData columns (total 3 columns):\n #   Column       Non-Null Count  Dtype              \n---  ------       --------------  -----              \n 0   article_id   889 non-null    object             \n 1   publishedAt  889 non-null    datetime64[ns, UTC]\n 2   text         889 non-null    object             \ndtypes: datetime64[ns, UTC](1), object(2)\nmemory usage: 21.0+ KB\n"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "sql = \"\"\"\n",
    "    SELECT \n",
    "        article_id,\n",
    "        publishedAt,\n",
    "        CONCAT(title, '. ', description, '. ', content) AS text\n",
    "    FROM `news-site-280319.news.articles`\n",
    "    WHERE\n",
    "      title IS NOT NULL\n",
    "      AND description IS NOT NULL\n",
    "      AND content IS NOT NULL\n",
    "      AND DATE(publishedAt) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(sql).to_dataframe()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             article_id               publishedAt  \\\n0  3a9144f9-f74d-4362-86a6-ae75cc47930c 2020-09-26 11:48:25+00:00   \n1  7e68d7c5-b7e8-46bc-a25e-ccd5b39c921e 2020-09-26 10:06:00+00:00   \n2  8313acac-487a-4437-86f0-2882fedaf907 2020-09-26 11:06:00+00:00   \n3  c65d1095-ebc1-41a4-871e-e8575c2c8859 2020-09-26 10:44:53+00:00   \n4  0923ad9f-e2de-43d3-a864-89fcb4dd60f8 2020-09-26 10:43:27+00:00   \n\n                                                text  \n0  Police break up parties at Edinburgh student h...  \n1  2020/09/26 10:00 GMT. The latest five minute n...  \n2  2020/09/26 11:00 GMT. The latest five minute n...  \n3  Fleetwood Town v AFC Wimbledon. Live coverage ...  \n4  Queens Park Rangers v Middlesbrough. Live cove...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>publishedAt</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3a9144f9-f74d-4362-86a6-ae75cc47930c</td>\n      <td>2020-09-26 11:48:25+00:00</td>\n      <td>Police break up parties at Edinburgh student h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7e68d7c5-b7e8-46bc-a25e-ccd5b39c921e</td>\n      <td>2020-09-26 10:06:00+00:00</td>\n      <td>2020/09/26 10:00 GMT. The latest five minute n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8313acac-487a-4437-86f0-2882fedaf907</td>\n      <td>2020-09-26 11:06:00+00:00</td>\n      <td>2020/09/26 11:00 GMT. The latest five minute n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c65d1095-ebc1-41a4-871e-e8575c2c8859</td>\n      <td>2020-09-26 10:44:53+00:00</td>\n      <td>Fleetwood Town v AFC Wimbledon. Live coverage ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0923ad9f-e2de-43d3-a864-89fcb4dd60f8</td>\n      <td>2020-09-26 10:43:27+00:00</td>\n      <td>Queens Park Rangers v Middlesbrough. Live cove...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    Police break up parties at Edinburgh student h...\n1    2020/09/26 10:00 GMT. The latest five minute n...\n2    2020/09/26 11:00 GMT. The latest five minute n...\n3    Fleetwood Town v AFC Wimbledon. Live coverage ...\n4    Queens Park Rangers v Middlesbrough. Live cove...\nName: text, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "news_text = df['text']\n",
    "\n",
    "news_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all new line returns with spaces\n",
    "news_text = news_text.str.replace('\\r\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "news_text = news_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(doc):\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update stop words list\n",
    "custom_stop_list = [\"char\", \"   \", \"  \", \"|\", \"reuters\"]\n",
    "nlp.Defaults.stop_words.update(custom_stop_list)\n",
    "\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "# Iterates through each article in the corpus.\n",
    "for doc in news_text:\n",
    "    # Passes that article through the pipeline and adds to a new list.\n",
    "    pr = nlp(doc)\n",
    "    doc_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates mapping of word IDs to words.\n",
    "words = corpora.Dictionary(doc_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=0,\n",
    "                                           update_every=1,\n",
    "                                           passes=100,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0,\n  &#39;0.049*&quot;trump&quot; + 0.032*&quot;president&quot; + 0.021*&quot;covid-19&quot; + 0.015*&quot;house&quot; + &#39;\n  &#39;0.014*&quot;white&quot; + 0.012*&quot;walter&quot; + 0.012*&quot;reed&quot; + 0.011*&quot;military&quot; + &#39;\n  &#39;0.011*&quot;coronavirus&quot; + 0.010*&quot;donald&quot;&#39;),\n (1,\n  &#39;0.025*&quot;reuters&quot; + 0.016*&quot;6&quot; + 0.010*&quot;google&quot; + 0.009*&quot;16&quot; + 0.008*&quot;staff&quot; + &#39;\n  &#39;0.007*&quot;4&quot; + 0.007*&quot;victory&quot; + 0.007*&quot;&gt;&quot; + 0.007*&quot;&lt;&quot; + 0.007*&quot;7&quot;&#39;),\n (2,\n  &#39;0.062*&quot;trump&quot; + 0.039*&quot;president&quot; + 0.020*&quot;donald&quot; + 0.015*&quot;biden&quot; + &#39;\n  &#39;0.015*&quot;u.s&quot; + 0.015*&quot;presidential&quot; + 0.014*&quot;coronavirus&quot; + 0.014*&quot;debate&quot; + &#39;\n  &#39;0.012*&quot;test&quot; + 0.010*&quot;chinese&quot;&#39;),\n (3,\n  &#39;0.009*&quot;night&quot; + 0.009*&quot;launch&quot; + 0.008*&quot;david&quot; + 0.007*&quot;image&quot; + &#39;\n  &#39;0.007*&quot;packers&quot; + 0.006*&quot;game&quot; + 0.006*&quot;rule&quot; + 0.006*&quot;monday&quot; + &#39;\n  &#39;0.006*&quot;coronavirus&quot; + 0.006*&quot;koo&quot;&#39;),\n (4,\n  &#39;0.015*&quot;reuters&quot; + 0.013*&quot;coronavirus&quot; + 0.012*&quot;new&quot; + 0.010*&quot;pixel&quot; + &#39;\n  &#39;0.009*&quot;5&quot; + 0.008*&quot;record&quot; + 0.008*&quot;google&quot; + 0.008*&quot;case&quot; + 0.007*&quot;7&quot; + &#39;\n  &#39;0.006*&quot;covid-19&quot;&#39;),\n (5,\n  &#39;0.021*&quot;reuters&quot; + 0.009*&quot;canadian&quot; + 0.009*&quot;year&quot; + 0.007*&quot;3&quot; + 0.007*&quot;win&quot; &#39;\n  &#39;+ 0.007*&quot;teenager&quot; + 0.007*&quot;5&quot; + 0.007*&quot;lead&quot; + 0.006*&quot;french&quot; + &#39;\n  &#39;0.006*&quot;saturday&quot;&#39;),\n (6,\n  &#39;0.011*&quot;reuters&quot; + 0.010*&quot;man&quot; + 0.010*&quot;police&quot; + 0.007*&quot;attack&quot; + &#39;\n  &#39;0.007*&quot;home&quot; + 0.007*&quot;video&quot; + 0.006*&quot;suspect&quot; + 0.006*&quot;rape&quot; + &#39;\n  &#39;0.006*&quot;united&quot; + 0.005*&quot;people&quot;&#39;),\n (7,\n  &#39;0.032*&quot;reuters&quot; + 0.011*&quot;new&quot; + 0.011*&quot;file&quot; + 0.010*&quot;photo&quot; + &#39;\n  &#39;0.010*&quot;staff&quot; + 0.007*&quot;covid-19&quot; + 0.007*&quot;company&quot; + 0.006*&quot;positive&quot; + &#39;\n  &#39;0.006*&quot;late&quot; + 0.005*&quot;test&quot;&#39;),\n (8,\n  &#39;0.020*&quot;reuters&quot; + 0.012*&quot;saturday&quot; + 0.010*&quot;russia&quot; + 0.009*&quot;far&quot; + &#39;\n  &#39;0.009*&quot;east&quot; + 0.009*&quot;ecological&quot; + 0.009*&quot;disaster&quot; + 0.009*&quot;pollution&quot; + &#39;\n  &#39;0.008*&quot;water&quot; + 0.007*&quot;away&quot;&#39;),\n (9,\n  &#39;0.017*&quot;covid-19&quot; + 0.013*&quot;reuters&quot; + 0.010*&quot;mean&quot; + 0.009*&quot;girl&quot; + &#39;\n  &#39;0.009*&quot;day&quot; + 0.006*&quot;report&quot; + 0.006*&quot;minister&quot; + 0.005*&quot;disease&quot; + &#39;\n  &#39;0.005*&quot;people&quot; + 0.005*&quot;new&quot;&#39;),\n (10,\n  &#39;0.014*&quot;reuters&quot; + 0.011*&quot;saturday&quot; + 0.010*&quot;coach&quot; + 0.009*&quot;new&quot; + &#39;\n  &#39;0.009*&quot;head&quot; + 0.008*&quot;european&quot; + 0.007*&quot;2020&quot; + 0.007*&quot;time&quot; + &#39;\n  &#39;0.007*&quot;photo&quot; + 0.007*&quot;river&quot;&#39;),\n (11,\n  &#39;0.028*&quot;reuters&quot; + 0.008*&quot;staff&quot; + 0.008*&quot;prime&quot; + 0.008*&quot;minister&quot; + &#39;\n  &#39;0.007*&quot;billion&quot; + 0.007*&quot;russian&quot; + 0.007*&quot;hamilton&quot; + 0.006*&quot;grand&quot; + &#39;\n  &#39;0.006*&quot;johnson&quot; + 0.006*&quot;world&quot;&#39;),\n (12,\n  &#39;0.020*&quot;reuters&quot; + 0.018*&quot;everton&quot; + 0.016*&quot;league&quot; + 0.015*&quot;score&quot; + &#39;\n  &#39;0.014*&quot;4&quot; + 0.014*&quot;season&quot; + 0.013*&quot;brighton&quot; + 0.013*&quot;premier&quot; + &#39;\n  &#39;0.013*&quot;saturday&quot; + 0.013*&quot;twice&quot;&#39;),\n (13,\n  &#39;0.020*&quot;u.s&quot; + 0.017*&quot;reuters&quot; + 0.012*&quot;senate&quot; + 0.010*&quot;covid-19&quot; + &#39;\n  &#39;0.008*&quot;mcconnell&quot; + 0.008*&quot;new&quot; + 0.007*&quot;floor&quot; + 0.007*&quot;court&quot; + &#39;\n  &#39;0.007*&quot;leader&quot; + 0.006*&quot;school&quot;&#39;),\n (14,\n  &#39;0.019*&quot;reuters&quot; + 0.017*&quot;fight&quot; + 0.016*&quot;u.s&quot; + 0.015*&quot;future&quot; + &#39;\n  &#39;0.012*&quot;new&quot; + 0.012*&quot;stock&quot; + 0.011*&quot;ufc&quot; + 0.009*&quot;ahead&quot; + 0.008*&quot;datum&quot; + &#39;\n  &#39;0.008*&quot;index&quot;&#39;),\n (15,\n  &#39;0.017*&quot;open&quot; + 0.016*&quot;french&quot; + 0.011*&quot;trump&quot; + 0.011*&quot;launch&quot; + &#39;\n  &#39;0.011*&quot;president&quot; + 0.011*&quot;new&quot; + 0.010*&quot;reuters&quot; + 0.010*&quot;&gt;&quot; + &#39;\n  &#39;0.010*&quot;coronavirus&quot; + 0.009*&quot;space&quot;&#39;),\n (16,\n  &#39;0.030*&quot;court&quot; + 0.024*&quot;supreme&quot; + 0.017*&quot;barrett&quot; + 0.017*&quot;reuters&quot; + &#39;\n  &#39;0.017*&quot;trump&quot; + 0.014*&quot;coney&quot; + 0.014*&quot;amy&quot; + 0.011*&quot;president&quot; + &#39;\n  &#39;0.010*&quot;nominee&quot; + 0.009*&quot;u.s&quot;&#39;),\n (17,\n  &#39;0.009*&quot;use&quot; + 0.007*&quot;doc&quot; + 0.007*&quot;nba&quot; + 0.007*&quot;river&quot; + 0.007*&quot;area&quot; + &#39;\n  &#39;0.006*&quot;price&quot; + 0.006*&quot;ap&quot; + 0.006*&quot;poll&quot; + 0.005*&quot;season&quot; + 0.005*&quot;day&quot;&#39;),\n (18,\n  &#39;0.009*&quot;android&quot; + 0.008*&quot;czech&quot; + 0.008*&quot;second&quot; + 0.007*&quot;11&quot; + 0.007*&quot;app&quot; &#39;\n  &#39;+ 0.007*&quot;support&quot; + 0.006*&quot;coronavirus&quot; + 0.006*&quot;party&quot; + 0.006*&quot;babis&quot; + &#39;\n  &#39;0.006*&quot;drug&quot;&#39;),\n (19,\n  &#39;0.016*&quot;armenia&quot; + 0.016*&quot;new&quot; + 0.014*&quot;karabakh&quot; + 0.013*&quot;nagorno&quot; + &#39;\n  &#39;0.012*&quot;reuters&quot; + 0.012*&quot;azerbaijan&quot; + 0.010*&quot;region&quot; + 0.008*&quot;2&quot; + &#39;\n  &#39;0.008*&quot;york&quot; + 0.007*&quot;4&quot;&#39;)]\n"
    }
   ],
   "source": [
    "pprint(lda_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   document_no  dominant_topic  topic_perc_contrib  \\\n0            0             0.0              0.9917   \n1            1            12.0              0.9848   \n2            2            12.0              0.9848   \n3            3            12.0              0.6141   \n4            4             1.0              0.6045   \n\n                                            keywords  \\\n0  trump, president, covid-19, house, white, walt...   \n1  reuters, everton, league, score, 4, season, br...   \n2  reuters, everton, league, score, 4, season, br...   \n3  reuters, everton, league, score, 4, season, br...   \n4  reuters, 6, google, 16, staff, 4, victory, &gt;, ...   \n\n                                                text  \n0  police break up parties at edinburgh student h...  \n1  2020/09/26 10:00 gmt. the latest five minute n...  \n2  2020/09/26 11:00 gmt. the latest five minute n...  \n3  fleetwood town v afc wimbledon. live coverage ...  \n4  queens park rangers v middlesbrough. live cove...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document_no</th>\n      <th>dominant_topic</th>\n      <th>topic_perc_contrib</th>\n      <th>keywords</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.9917</td>\n      <td>trump, president, covid-19, house, white, walt...</td>\n      <td>police break up parties at edinburgh student h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>12.0</td>\n      <td>0.9848</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n      <td>2020/09/26 10:00 gmt. the latest five minute n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>12.0</td>\n      <td>0.9848</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n      <td>2020/09/26 11:00 gmt. the latest five minute n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12.0</td>\n      <td>0.6141</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n      <td>fleetwood town v afc wimbledon. live coverage ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.6045</td>\n      <td>reuters, 6, google, 16, staff, 4, victory, &gt;, ...</td>\n      <td>queens park rangers v middlesbrough. live cove...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pandas.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(\n",
    "                        pandas.Series(\n",
    "                            [int(topic_num), round(prop_topic,4),topic_keywords]\n",
    "                        ), ignore_index=True\n",
    "                    )\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['dominant_topic', 'perc_contribution', 'topic_keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pandas.Series(texts)\n",
    "    sent_topics_df = pandas.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=news_text)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['document_no', 'dominant_topic', 'topic_perc_contrib', 'keywords', 'text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group top 5 sentences under each topic\n",
    "# sent_topics_sorteddf = pandas.DataFrame()\n",
    "\n",
    "# sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('dominant_topic')\n",
    "\n",
    "# for i, grp in sent_topics_outdf_grpd:\n",
    "#     sent_topics_sorteddf = pandas.concat([sent_topics_sorteddf, \n",
    "#                                              grp.sort_values(['perc_contribution'], \n",
    "#                                              ascending=[0]).head(1)],\n",
    "#                                              axis=0\n",
    "#                                              )\n",
    "\n",
    "# # Reset Index    \n",
    "# sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Format\n",
    "# sent_topics_sorteddf.columns = ['topic_Num', 'perc_Contribution', 'keywords', 'text']\n",
    "\n",
    "# # Show\n",
    "# sent_topics_sorteddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   dominant_topic                                     topic_keywords  \\\n0             0.0  trump, president, covid-19, house, white, walt...   \n1             1.0  reuters, 6, google, 16, staff, 4, victory, &gt;, ...   \n4             4.0  reuters, coronavirus, new, pixel, 5, record, g...   \n2             2.0  trump, president, donald, biden, u.s, presiden...   \n3             3.0  night, launch, david, image, packers, game, ru...   \n\n   num_documents  perc_documents  \n0             58        6.524184  \n1             53        5.961755  \n4             53        5.961755  \n2             48        5.399325  \n3             30        3.374578  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dominant_topic</th>\n      <th>topic_keywords</th>\n      <th>num_documents</th>\n      <th>perc_documents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>trump, president, covid-19, house, white, walt...</td>\n      <td>58</td>\n      <td>6.524184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>reuters, 6, google, 16, staff, 4, victory, &gt;, ...</td>\n      <td>53</td>\n      <td>5.961755</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>reuters, coronavirus, new, pixel, 5, record, g...</td>\n      <td>53</td>\n      <td>5.961755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>trump, president, donald, biden, u.s, presiden...</td>\n      <td>48</td>\n      <td>5.399325</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>night, launch, david, image, packers, game, ru...</td>\n      <td>30</td>\n      <td>3.374578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['dominant_topic'].value_counts()\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['dominant_topic', 'topic_keywords']].groupby(\n",
    "                        ['dominant_topic', 'topic_keywords']\n",
    "                    )['topic_keywords'].count().reset_index(name='num_documents')\n",
    "\n",
    "topic_num_keywords['perc_documents'] = ((topic_num_keywords['num_documents'])/(topic_num_keywords['num_documents'].sum()))*100\n",
    "\n",
    "# show top topics\n",
    "topic_num_keywords.head(5).sort_values(by='perc_documents', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                               article_id               publishedAt  \\\n0    3a9144f9-f74d-4362-86a6-ae75cc47930c 2020-09-26 11:48:25+00:00   \n1    7e68d7c5-b7e8-46bc-a25e-ccd5b39c921e 2020-09-26 10:06:00+00:00   \n2    8313acac-487a-4437-86f0-2882fedaf907 2020-09-26 11:06:00+00:00   \n3    c65d1095-ebc1-41a4-871e-e8575c2c8859 2020-09-26 10:44:53+00:00   \n4    0923ad9f-e2de-43d3-a864-89fcb4dd60f8 2020-09-26 10:43:27+00:00   \n..                                    ...                       ...   \n884  9c88b86d-2ebe-49be-9dc0-1518038adb44 2020-10-01 11:00:00+00:00   \n885  b7b9928f-909b-4edb-9921-dbe4c7e2ce4d 2020-10-01 11:17:55+00:00   \n886  87f165b7-4e6e-4cd1-a365-ebd4d5ac7dee 2020-10-01 10:57:30+00:00   \n887  aea97082-cab0-4e9c-9bd6-4b09f76f75a7 2020-10-01 10:59:02+00:00   \n888  1cc6ce29-2bca-47d0-86ea-66eb863f3ce2 2020-09-29 11:52:23+00:00   \n\n                                                  text  dominant_topic  \\\n0    police break up parties at edinburgh student h...               0   \n1    2020/09/26 10:00 gmt. the latest five minute n...              12   \n2    2020/09/26 11:00 gmt. the latest five minute n...              12   \n3    fleetwood town v afc wimbledon. live coverage ...              12   \n4    queens park rangers v middlesbrough. live cove...               1   \n..                                                 ...             ...   \n884  focus-meatpackers in the americas accelerate a...               0   \n885  ask the captain: how does ice on the wing affe...               3   \n886  us jobless claims likely remained high as layo...               6   \n887  coronavirus updates: massive airline layoffs c...               4   \n888  national coffee day 2020 deals from dunkin&#39;, s...               0   \n\n     topic_perc_contrib                                           keywords  \n0                0.9917  trump, president, covid-19, house, white, walt...  \n1                0.9848  reuters, everton, league, score, 4, season, br...  \n2                0.9848  reuters, everton, league, score, 4, season, br...  \n3                0.6141  reuters, everton, league, score, 4, season, br...  \n4                0.6045  reuters, 6, google, 16, staff, 4, victory, &gt;, ...  \n..                  ...                                                ...  \n884              0.9947  trump, president, covid-19, house, white, walt...  \n885              0.9932  night, launch, david, image, packers, game, ru...  \n886              0.9941  reuters, man, police, attack, home, video, sus...  \n887              0.9949  reuters, coronavirus, new, pixel, 5, record, g...  \n888              0.6559  trump, president, covid-19, house, white, walt...  \n\n[889 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>publishedAt</th>\n      <th>text</th>\n      <th>dominant_topic</th>\n      <th>topic_perc_contrib</th>\n      <th>keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3a9144f9-f74d-4362-86a6-ae75cc47930c</td>\n      <td>2020-09-26 11:48:25+00:00</td>\n      <td>police break up parties at edinburgh student h...</td>\n      <td>0</td>\n      <td>0.9917</td>\n      <td>trump, president, covid-19, house, white, walt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7e68d7c5-b7e8-46bc-a25e-ccd5b39c921e</td>\n      <td>2020-09-26 10:06:00+00:00</td>\n      <td>2020/09/26 10:00 gmt. the latest five minute n...</td>\n      <td>12</td>\n      <td>0.9848</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8313acac-487a-4437-86f0-2882fedaf907</td>\n      <td>2020-09-26 11:06:00+00:00</td>\n      <td>2020/09/26 11:00 gmt. the latest five minute n...</td>\n      <td>12</td>\n      <td>0.9848</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c65d1095-ebc1-41a4-871e-e8575c2c8859</td>\n      <td>2020-09-26 10:44:53+00:00</td>\n      <td>fleetwood town v afc wimbledon. live coverage ...</td>\n      <td>12</td>\n      <td>0.6141</td>\n      <td>reuters, everton, league, score, 4, season, br...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0923ad9f-e2de-43d3-a864-89fcb4dd60f8</td>\n      <td>2020-09-26 10:43:27+00:00</td>\n      <td>queens park rangers v middlesbrough. live cove...</td>\n      <td>1</td>\n      <td>0.6045</td>\n      <td>reuters, 6, google, 16, staff, 4, victory, &gt;, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>9c88b86d-2ebe-49be-9dc0-1518038adb44</td>\n      <td>2020-10-01 11:00:00+00:00</td>\n      <td>focus-meatpackers in the americas accelerate a...</td>\n      <td>0</td>\n      <td>0.9947</td>\n      <td>trump, president, covid-19, house, white, walt...</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>b7b9928f-909b-4edb-9921-dbe4c7e2ce4d</td>\n      <td>2020-10-01 11:17:55+00:00</td>\n      <td>ask the captain: how does ice on the wing affe...</td>\n      <td>3</td>\n      <td>0.9932</td>\n      <td>night, launch, david, image, packers, game, ru...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>87f165b7-4e6e-4cd1-a365-ebd4d5ac7dee</td>\n      <td>2020-10-01 10:57:30+00:00</td>\n      <td>us jobless claims likely remained high as layo...</td>\n      <td>6</td>\n      <td>0.9941</td>\n      <td>reuters, man, police, attack, home, video, sus...</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>aea97082-cab0-4e9c-9bd6-4b09f76f75a7</td>\n      <td>2020-10-01 10:59:02+00:00</td>\n      <td>coronavirus updates: massive airline layoffs c...</td>\n      <td>4</td>\n      <td>0.9949</td>\n      <td>reuters, coronavirus, new, pixel, 5, record, g...</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>1cc6ce29-2bca-47d0-86ea-66eb863f3ce2</td>\n      <td>2020-09-29 11:52:23+00:00</td>\n      <td>national coffee day 2020 deals from dunkin', s...</td>\n      <td>0</td>\n      <td>0.6559</td>\n      <td>trump, president, covid-19, house, white, walt...</td>\n    </tr>\n  </tbody>\n</table>\n<p>889 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "output_df = pandas.concat([df[['article_id', 'publishedAt']], news_text, df_dominant_topic], axis=1)\n",
    "\n",
    "output_df.columns = ['article_id', 'publishedAt', 'text', 'drop', 'dominant_topic', 'topic_perc_contrib', 'keywords', 'drop']\n",
    "\n",
    "output_df.drop(output_df['drop'], axis=1, inplace=True)\n",
    "\n",
    "output_df['dominant_topic'] = output_df['dominant_topic'].astype(int)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure BigQuery job\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"article_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"publishedAt\", bigquery.enums.SqlTypeNames.TIMESTAMP),\n",
    "        bigquery.SchemaField(\"text\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"dominant_topic\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"topic_perc_contrib\", bigquery.enums.SqlTypeNames.FLOAT64),\n",
    "        bigquery.SchemaField(\"keywords\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;google.cloud.bigquery.job.LoadJob at 0x12ca69ee0&gt;"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "table_id = \"news-site-280319.topics.article_topics\"\n",
    "job = client.load_table_from_dataframe(\n",
    "    output_df,\n",
    "    table_id, \n",
    "    job_config=job_config\n",
    ")  # Make an API request.\n",
    "job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;DONE&#39;"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# check job status\n",
    "job.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit9c1e0c45891f4f5bb47cc2daf8211df6",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}